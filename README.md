# Upwork AI Assistant - Feed Aggregator Edition

**Lysa** - AI Assistant phÃ¢n tÃ­ch job market tá»« nhiá»u nguá»“n an toÃ n, há»£p phÃ¡p.

## ğŸ¯ Äáº·c Ä‘iá»ƒm

- âœ… **100% An toÃ n**: KhÃ´ng Ä‘á»¥ng vÃ o Upwork, khÃ´ng vi pháº¡m ToS
- âœ… **Nhiá»u nguá»“n**: 20+ job boards, tech blogs, RSS feeds há»£p phÃ¡p
- âœ… **AI thÃ´ng minh**: PhÃ¢n tÃ­ch job theo CEO MODE 7-tier, há»c trend tá»± Ä‘á»™ng
- âœ… **Tá»± Ä‘á»™ng hÃ³a**: GitHub Actions crawl má»—i 15 phÃºt
- âœ… **Local AI**: Cháº¡y trÃªn Ollama local, khÃ´ng cáº§n API key

## ğŸ“‹ YÃªu cáº§u

- Python 3.10
- Ollama vá»›i model `qwen2.5:7b-instruct-q4_K_M`
- Git

## ğŸš€ Setup

### 1. Clone repository

```bash
git clone https://github.com/babyfox1306/Upwork-AI-Assistant.git
cd Upwork-AI-Assistant
```

### 2. Setup Python environment

```bash
# Windows
setup.bat

# Linux/Mac
python -m venv venv
source venv/bin/activate  # hoáº·c venv\Scripts\activate trÃªn Windows
pip install -r requirements.txt
```

### 3. Setup Ollama

```bash
# CÃ i Ollama náº¿u chÆ°a cÃ³
# https://ollama.ai

# Pull model
ollama pull qwen2.5:7b-instruct-q4_K_M
ollama pull all-minilm
```

### 4. Cáº¥u hÃ¬nh

Chá»‰nh sá»­a `config/profile.yaml` vá»›i thÃ´ng tin cá»§a báº¡n:
- Skills
- Experience
- Rate
- Portfolio

## ğŸ“– Sá»­ dá»¥ng

### Cáº­p nháº­t dá»¯ liá»‡u

```bash
# Windows
update.bat

# Hoáº·c manual
python scripts/crawl_multi_source.py
python scripts/local_sync_and_rag.py
python scripts/analyze_and_summarize.py
```

### Chat vá»›i AI

```bash
# Windows
chat.bat

# Hoáº·c manual
streamlit run app.py
```

Má»Ÿ trÃ¬nh duyá»‡t táº¡i `http://localhost:8501`

### PhÃ¢n tÃ­ch job cá»¥ thá»ƒ

```python
from ai.analyser import analyse_job

job = {
    'title': 'Python Web Scraping',
    'description': '...',
    'budget': '$500'
}

result = analyse_job(job)
print(result)
```

### Generate proposal

```python
from ai.generator import generate_proposal

proposal = generate_proposal(job_id='abc123')
# hoáº·c
proposal = generate_proposal(job_link='https://...')
```

### Xem daily summary

```python
from ai.summarizer import generate_daily_summary

summary = generate_daily_summary()
print(summary['summary'])
```

## ğŸ“ Cáº¥u trÃºc

```
Upwork-AI-Assistant/
â”œâ”€â”€ ai/                      # AI modules
â”‚   â”œâ”€â”€ analyser.py         # PhÃ¢n tÃ­ch job (7-tier CEO MODE)
â”‚   â”œâ”€â”€ summarizer.py       # TÃ³m táº¯t trend hÃ ng ngÃ y/tuáº§n
â”‚   â””â”€â”€ generator.py        # Generate proposal draft
â”œâ”€â”€ ai_rules/               # AI instructions
â”‚   â”œâ”€â”€ analysis.md         # System instruction
â”‚   â”œâ”€â”€ upwork_rules.md     # Rulebook
â”‚   â”œâ”€â”€ examples.json       # Few-shot examples
â”‚   â””â”€â”€ hardware.md         # Hardware constraints
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml         # RSS feeds, Ollama config
â”‚   â”œâ”€â”€ profile.yaml        # CEO profile
â”‚   â””â”€â”€ proposal_template.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_jobs.jsonl      # Jobs tá»« RSS (git tracked)
â”‚   â”œâ”€â”€ feeds/              # Tech blog feeds (gitignore)
â”‚   â”œâ”€â”€ trends/             # Daily/weekly summaries
â”‚   â”œâ”€â”€ analyses/           # AI analyses
â”‚   â””â”€â”€ chroma_db/          # Vector DB (gitignore)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ crawl_multi_source.py    # Crawl RSS feeds
â”‚   â”œâ”€â”€ local_sync_and_rag.py     # Sync + embed + ChromaDB
â”‚   â”œâ”€â”€ analyze_and_summarize.py  # AI analysis + summary
â”‚   â”œâ”€â”€ query_ai.py               # Query AI
â”‚   â””â”€â”€ generator.py              # Generate proposal
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ crawl.yml           # GitHub Actions (crawl má»—i 15 phÃºt)
â”œâ”€â”€ app.py                   # Streamlit chat interface
â”œâ”€â”€ update.bat               # Update script (Windows)
â””â”€â”€ chat.bat                 # Chat script (Windows)
```

## ğŸ”§ Cáº¥u hÃ¬nh RSS Feeds

Chá»‰nh sá»­a `config/config.yaml` Ä‘á»ƒ thÃªm/báº­t/táº¯t RSS feeds:

```yaml
sources:
  job_boards:
    - name: "We Work Remotely"
      url: "https://..."
      enabled: true
      category: "jobs"
  
  tech_blogs:
    - name: "OpenAI Blog"
      url: "https://openai.com/blog/rss.xml"
      enabled: true
      category: "trends"
  
  google_alerts:
    - name: "AI Freelance Remote"
      url: ""  # Paste RSS URL tá»« Google Alerts
      enabled: false
```

### Setup Google Alerts RSS

1. VÃ o https://www.google.com/alerts
2. Táº¡o alert vá»›i tá»« khÃ³a (vÃ­ dá»¥: "AI freelance remote")
3. Chá»n "Deliver to: RSS feed"
4. Copy RSS URL vÃ o `config/config.yaml`

## ğŸ¤– AI Analysis - CEO MODE 7-Tier

Lysa phÃ¢n tÃ­ch má»—i job theo 7 táº§ng:

1. **INTENT ANALYSIS** - LÃ½ do khÃ¡ch post job
2. **TECH FEASIBILITY** - CÃ³ gÃ¬ khÃ´ng thá»±c táº¿?
3. **SCOPE CREEP DETECTION** - MÃ¹i phÃ¬nh scope
4. **ROI CHECK REAL** - Lá»i bao nhiÃªu theo giá»?
5. **COMPETITION INTEL** - Sá»‘ proposal, cheap labor trap
6. **TIER MATCHING** - Job nÃ y há»£p vá»›i mÃ¬nh khÃ´ng?
7. **VERDICT** - CHá»T: NÃªn láº¥y / KhÃ´ng nÃªn

## ğŸ”„ GitHub Actions

Workflow tá»± Ä‘á»™ng:
- Crawl RSS feeds má»—i 15 phÃºt
- Commit jobs má»›i vÃ o repo
- Pull vá» local Ä‘á»ƒ AI phÃ¢n tÃ­ch

## ğŸ“Š Data Flow

```
GitHub Actions (15 phÃºt/láº§n)
    â†“
Crawl RSS Feeds (job boards, tech blogs)
    â†“
Commit vÃ o data/raw_jobs.jsonl
    â†“
Local: git pull
    â†“
AI Analysis (analyser.py)
    â†“
Daily/Weekly Summary (summarizer.py)
    â†“
ChromaDB (vector search)
    â†“
Streamlit Chat Interface
```

## ğŸ›¡ï¸ An toÃ n

- âœ… KhÃ´ng crawl Upwork
- âœ… Chá»‰ dÃ¹ng RSS feeds cÃ´ng khai
- âœ… KhÃ´ng vi pháº¡m ToS
- âœ… KhÃ´ng cáº§n API keys (trá»« Ollama local)
- âœ… Táº¥t cáº£ nguá»“n Ä‘á»u há»£p phÃ¡p

## ğŸ“ License

MIT

## ğŸ¤ Contributing

Pull requests welcome!

---

**Lysa** - Your AI Job Market Analyst ğŸ¤–

