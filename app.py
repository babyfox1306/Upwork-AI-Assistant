#!/usr/bin/env python3
"""
Streamlit Web App - Upwork AI Assistant Chat Interface
"""

import streamlit as st
import yaml
from pathlib import Path
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import sys

try:
    from ollama import Client
    OLLAMA_CLIENT = True
except ImportError:
    try:
        import ollama
        OLLAMA_CLIENT = False
    except ImportError:
        st.error("‚ö† L·ªói: Kh√¥ng t√¨m th·∫•y ollama. H√£y c√†i: pip install ollama")
        st.stop()

sys.path.insert(0, str(Path(__file__).parent))

# Load config
@st.cache_resource
def load_config():
    config_path = Path(__file__).parent / 'config' / 'config.yaml'
    profile_path = Path(__file__).parent / 'config' / 'profile.yaml'
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    with open(profile_path, 'r', encoding='utf-8') as f:
        profile = yaml.safe_load(f)
    
    return config, profile

@st.cache_resource
def init_chromadb():
    """Kh·ªüi t·∫°o ChromaDB"""
    config, _ = load_config()
    chromadb_config = config['chromadb']
    persist_dir = Path(__file__).parent / chromadb_config['persist_directory']
    
    client = chromadb.PersistentClient(
        path=str(persist_dir),
        settings=Settings(anonymized_telemetry=False)
    )
    collection = client.get_collection(chromadb_config['collection_name'])
    return collection

def search_jobs(collection, query_text, top_k=10):
    """Search jobs trong ChromaDB"""
    model = SentenceTransformer('all-MiniLM-L6-v2')
    query_embedding = model.encode([query_text])[0].tolist()
    
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )
    
    jobs = []
    if results['ids'] and len(results['ids'][0]) > 0:
        for i in range(len(results['ids'][0])):
            job = {
                'job_id': results['ids'][0][i],
                'title': results['metadatas'][0][i].get('title', ''),
                'description': results['documents'][0][i],
                'budget': results['metadatas'][0][i].get('budget', ''),
                'proposals': results['metadatas'][0][i].get('proposals', ''),
                'client_country': results['metadatas'][0][i].get('client_country', ''),
                'category': results['metadatas'][0][i].get('category', ''),
                'link': results['metadatas'][0][i].get('link', ''),
                'source': results['metadatas'][0][i].get('source', 'Unknown'),
            }
            jobs.append(job)
    
    return jobs

def chat_with_ai(user_input, collection, conversation_history):
    """Chat v·ªõi AI"""
    config, profile = load_config()
    ollama_config = config['ollama']
    base_url = ollama_config.get('base_url', 'http://localhost:11434')
    
    # Build context
    context = f"""
Profile CEO:
- Skills: {', '.join(profile.get('skills', []))}
- Experience: {profile.get('experience', 0)} nƒÉm
- Rate: {profile.get('rate', '')}
"""
    
    # N·∫øu user h·ªèi v·ªÅ jobs, search tr∆∞·ªõc
    if any(keyword in user_input.lower() for keyword in ['job', 'vi·ªác', 't√¨m', 'search', 'ph√¢n t√≠ch']):
        jobs = search_jobs(collection, user_input, top_k=5)
        if jobs:
            context += f"\n\nJobs t√¨m ƒë∆∞·ª£c:\n"
            for i, job in enumerate(jobs, 1):
                context += f"{i}. {job['title']}\n   Budget: {job.get('budget', 'N/A')}\n   Link: {job.get('link', 'N/A')}\n\n"
    
    # Load AI rules
    rules_dir = Path(__file__).parent / 'ai_rules'
    system_instruction = ""
    rulebook = ""
    hardware = ""
    
    analysis_file = rules_dir / 'analysis.md'
    if analysis_file.exists():
        with open(analysis_file, 'r', encoding='utf-8') as f:
            system_instruction = f.read()
    
    rules_file = rules_dir / 'upwork_rules.md'
    if rules_file.exists():
        with open(rules_file, 'r', encoding='utf-8') as f:
            rulebook = f.read()
    
    hardware_file = rules_dir / 'hardware.md'
    if hardware_file.exists():
        with open(hardware_file, 'r', encoding='utf-8') as f:
            hardware = f.read()
    
    # Build messages
    system_prompt = f"""{system_instruction}

{rulebook}

{hardware}"""
    
    messages = [
        {'role': 'system', 'content': system_prompt + '\n\n' + context}
    ]
    
    # Add conversation history
    messages.extend(conversation_history[-4:])
    
    # Add user input
    messages.append({'role': 'user', 'content': user_input})
    
    try:
        if OLLAMA_CLIENT:
            client = Client(host=base_url)
            response = client.chat(
                model=ollama_config['model'],
                messages=messages
            )
            return response['message']['content']
        else:
            response = ollama.chat(
                model=ollama_config['model'],
                messages=messages
            )
            return response['message']['content']
    except Exception as e:
        return f"L·ªói: {e}. ƒê·∫£m b·∫£o Ollama ƒëang ch·∫°y: ollama serve"

# Streamlit UI
st.set_page_config(
    page_title="Upwork AI Assistant",
    page_icon="üí¨",
    layout="wide"
)

st.title("üí¨ Upwork AI Assistant")
st.caption("Chat v·ªõi AI ƒë·ªÉ ph√¢n t√≠ch jobs, t∆∞ v·∫•n, v√† vi·∫øt proposal")

# Sidebar
with st.sidebar:
    st.header("üìä Th√¥ng tin")
    config, profile = load_config()
    st.write(f"**Skills:** {', '.join(profile.get('skills', []))}")
    st.write(f"**Experience:** {profile.get('experience', 0)} nƒÉm")
    st.write(f"**Rate:** {profile.get('rate', '')}")
    
    st.divider()
    
    st.header("üîß Actions")
    if st.button("üîÑ Refresh Jobs"):
        st.cache_resource.clear()
        st.rerun()
    
    if st.button("üì• Sync Data"):
        import subprocess
        with st.spinner("ƒêang sync..."):
            result = subprocess.run(
                ["python", "scripts/local_sync_and_rag.py"],
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                st.success("Sync th√†nh c√¥ng!")
            else:
                st.error(f"L·ªói: {result.stderr}")

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []

# Load ChromaDB
try:
    collection = init_chromadb()
except Exception as e:
    st.error(f"L·ªói kh·ªüi t·∫°o ChromaDB: {e}")
    st.stop()

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat input
if prompt := st.chat_input("H·ªèi g√¨ ƒë√≥ v·ªÅ jobs, proposal, ho·∫∑c t∆∞ v·∫•n..."):
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Get AI response
    with st.chat_message("assistant"):
        with st.spinner("ƒêang suy nghƒ©..."):
            response = chat_with_ai(
                prompt, 
                collection, 
                st.session_state.conversation_history
            )
            st.markdown(response)
    
    # Add assistant message
    st.session_state.messages.append({"role": "assistant", "content": response})
    
    # Update conversation history
    st.session_state.conversation_history.append({'role': 'user', 'content': prompt})
    st.session_state.conversation_history.append({'role': 'assistant', 'content': response})

# Quick actions
st.divider()
st.subheader("üí° G·ª£i √Ω c√¢u h·ªèi")

col1, col2, col3 = st.columns(3)

with col1:
    if st.button("üîç T√¨m jobs WordPress"):
        st.session_state.messages.append({"role": "user", "content": "T√¨m jobs WordPress cho em"})
        st.rerun()

with col2:
    if st.button("üìù Ph√¢n t√≠ch jobs m·ªõi"):
        st.session_state.messages.append({"role": "user", "content": "Ph√¢n t√≠ch jobs m·ªõi nh·∫•t cho em"})
        st.rerun()

with col3:
    if st.button("‚úçÔ∏è Vi·∫øt proposal"):
        st.session_state.messages.append({"role": "user", "content": "H∆∞·ªõng d·∫´n em vi·∫øt proposal"})
        st.rerun()

